python llama_eval.py \
    --model_name "meta-llama/Meta-Llama-3.1-8B" \
    --dataset cnn_dailymail \
    --split "test[:10]" \
    --compress_ratio 0.4 \
    --kv_method SimCalKV \
    --output_dir ./llama3.1-8b/results_optimize/nums_token1024+64

python llama_eval.py \
    --model_name "meta-llama/Meta-Llama-3.1-8B" \
    --dataset xsum \
    --split "test[:10]" \
    --compress_ratio 0.8 \
    --kv_method KeepKV \
    --output_dir ./llama3.1-8b/results_optimize/nums_token512+64

python llama_eval.py \
    --model_name "meta-llama/Meta-Llama-3.1-8B" \
    --dataset LongBench/gov_report \
    --split "train[:10]" \
    --compress_ratio 0.5 \
    --kv_method CaM \
    --output_dir ./llama3.1-8b/results_optimize/nums_token4096+512
